{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef432a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "DATA_DIR = \"dataset\"\n",
    "IMG_SIZE = (256, 256)\n",
    "RESIZE_TO = (64, 64)\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "# Split ratios\n",
    "TRAIN_SPLIT = 0.7   # 70% for training\n",
    "VAL_SPLIT = 0.2    # 20% for validation  \n",
    "TEST_SPLIT = 0.1   # 10% for testing\n",
    "\n",
    "CLASS_NAMES = ['Bacterial spot', 'Early blight', 'Late blight', 'Leaf Mold', 'Septoria leaf spot', 'Target Spot', 'Mosaic virus', 'Two-spotted spider mite', 'Yellow Leaf Curl Virus', 'Healthy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e98e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_tools import create_stratified_splits\n",
    "\n",
    "# Create stratified splits\n",
    "print(\"Creating stratified splits...\")\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test), class_names = create_stratified_splits(DATA_DIR, TRAIN_SPLIT, VAL_SPLIT, TEST_SPLIT, SEED)\n",
    "\n",
    "num_classes = len(class_names)\n",
    "print(f\"Found {num_classes} classes: {class_names}\")\n",
    "\n",
    "# Print distribution info\n",
    "total_samples = len(X_train) + len(X_val) + len(X_test)\n",
    "print(f\"\\nDataset distribution:\")\n",
    "print(f\"Train samples: {len(X_train)} ({len(X_train)/total_samples*100:.1f}%)\")\n",
    "print(f\"Validation samples: {len(X_val)} ({len(X_val)/total_samples*100:.1f}%)\")\n",
    "print(f\"Test samples: {len(X_test)} ({len(X_test)/total_samples*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b89919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution in each split\n",
    "print(f\"\\nClass distribution per split:\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    train_count = np.sum(y_train == i)\n",
    "    val_count = np.sum(y_val == i)\n",
    "    test_count = np.sum(y_test == i)\n",
    "    total_count = train_count + val_count + test_count\n",
    "    \n",
    "    print(f\"{class_name}:\")\n",
    "    print(f\"  Train: {train_count} ({train_count/total_count*100:.1f}%)\")\n",
    "    print(f\"  Val:   {val_count} ({val_count/total_count*100:.1f}%)\")\n",
    "    print(f\"  Test:  {test_count} ({test_count/total_count*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ebb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_tools import create_tf_dataset_from_paths\n",
    "# Create TensorFlow datasets\n",
    "\n",
    "print(\"\\nCreating TensorFlow datasets...\")\n",
    "train_ds = create_tf_dataset_from_paths(IMG_SIZE, X_train, y_train, BATCH_SIZE, seed=SEED, shuffle=True)\n",
    "val_ds = create_tf_dataset_from_paths(IMG_SIZE, X_val, y_val, BATCH_SIZE, seed=SEED, shuffle=False)\n",
    "test_ds = create_tf_dataset_from_paths(X_test, y_test, BATCH_SIZE, seed=SEED, shuffle=False)\n",
    "\n",
    "# Preprocessing function\n",
    "def resize_and_normalize(image, label):\n",
    "    image = tf.image.resize(image, RESIZE_TO)\n",
    "    image = image / 255.0\n",
    "    return image, label\n",
    "\n",
    "# Apply preprocessing\n",
    "train_ds = train_ds.map(resize_and_normalize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(resize_and_normalize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(resize_and_normalize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Optimize performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765c73bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import  MaxPooling2D, GlobalAveragePooling2D, Dense, DepthwiseConv2D, Dropout, Conv2D, LeakyReLU, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "activation = 'relu'\n",
    "\n",
    "# 3. Define a simple CNN model\n",
    "model = models.Sequential([\n",
    "    # Layer 1\n",
    "    DepthwiseConv2D(kernel_size=3, input_shape=RESIZE_TO + (3,), padding='same'),\n",
    "    Conv2D(16, 1, activation=activation),\n",
    "    MaxPooling2D(),\n",
    "   \n",
    "    # Layer 2\n",
    "    DepthwiseConv2D(kernel_size=3, padding='same'),\n",
    "    Conv2D(32, 1, activation=activation),\n",
    "    MaxPooling2D(),\n",
    "   \n",
    "    # Layer 3\n",
    "    DepthwiseConv2D(kernel_size=3, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, 1, activation=activation),\n",
    "    MaxPooling2D(),\n",
    "\n",
    "   \n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(32, activation=activation),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db182b8",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a028e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop()\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer= optimizer,\n",
    "    loss='sparse_categorical_crossentropy',  # or 'binary_crossentropy' for 2 classes\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51789fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Define your experiment configuration\n",
    "experiment_name = \"BN_no_Data_no_RMS\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = f\"logs/fit/{experiment_name}_{timestamp}\"\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=200,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_tools import plot_training_history\n",
    "\n",
    "plot_training_history(history, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f389a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_tools import show_sample_predictions\n",
    "\n",
    "show_sample_predictions(test_ds,model,class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf7e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_tools import comprehensive_evaluation\n",
    "\n",
    "results = comprehensive_evaluation(model, test_ds, CLASS_NAMES, experiment_name, save_plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee27cc5",
   "metadata": {},
   "source": [
    "## Save and Quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e19a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_name = f\"models\\\\{experiment_name}.h5\"\n",
    "model.save(model_name)\n",
    "\n",
    "size = os.path.getsize(model_name) / (1024)  # Convert to MB\n",
    "print(f\"Model size: {size:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9231d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8  # or tf.int8 depending on ESP32 support\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "def representative_dataset():\n",
    "    for image_batch, _ in train_ds.take(100):\n",
    "        for img in image_batch:\n",
    "            img = tf.cast(img, tf.float32)\n",
    "            img = tf.expand_dims(img, axis=0)  # Fix: make input 4D\n",
    "            yield [img]\n",
    "\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "# 5. Convert\n",
    "quantized_model = converter.convert()\n",
    "\n",
    "# 6. Save\n",
    "with open(f\"models\\\\{experiment_name}_quant.tflite\", \"wb\") as f:\n",
    "    f.write(quantized_model)\n",
    "\n",
    "print(\"TFLite model size:\", len(quantized_model) / 1024, \"KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f3a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantization_tools import evaluate_quantized_model\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=f\"models\\\\{experiment_name}_quant.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "def convert_to_uint8(image, label):\n",
    "    # Scale to 0-255 if your images are normalized (0-1 or -1 to 1)\n",
    "    image = tf.cast(image * 255.0, tf.uint8)\n",
    "    return image, label\n",
    "\n",
    "# Apply to your test dataset\n",
    "test_ds_uint8 = test_ds.map(convert_to_uint8)\n",
    "\n",
    "# Evaluate\n",
    "quantized_accuracy = evaluate_quantized_model(interpreter, test_ds_uint8)\n",
    "print(f\"Quantized model accuracy: {quantized_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4c7cc1",
   "metadata": {},
   "source": [
    "## QAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "# Apply quantization-aware training to the loaded model\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "q_aware_model = quantize_model(model)\n",
    "\n",
    "# Compile with a much lower learning rate\n",
    "q_aware_model.compile(\n",
    "    optimizer=optimizer,  # Very low LR\n",
    "    loss='sparse_categorical_crossentropy',  # Use your original loss\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fine-tune for just a few epochs\n",
    "qat_history = q_aware_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5,  # Start with just 3 epochs\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Check if accuracy is maintained\n",
    "print(f\"QAT model accuracy: {max(history.history['val_accuracy'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3bf18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = q_aware_model.evaluate(test_ds)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1918803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8  # or tf.int8 depending on ESP32 support\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "def representative_dataset():\n",
    "    for image_batch, _ in train_ds.take(100):\n",
    "        for img in image_batch:\n",
    "            img = tf.cast(img, tf.float32)\n",
    "            img = tf.expand_dims(img, axis=0)  # Fix: make input 4D\n",
    "            yield [img]\n",
    "\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "# 5. Convert\n",
    "quantized_model = converter.convert()\n",
    "\n",
    "# 6. Save\n",
    "with open(f\"models\\\\{experiment_name}__qat.tflite\", \"wb\") as f:\n",
    "    f.write(quantized_model)\n",
    "\n",
    "# Check model size\n",
    "import os\n",
    "original_size = os.path.getsize(f'models\\\\{experiment_name}.h5')\n",
    "quantized_size = os.path.getsize(f\"models\\\\{experiment_name}__qat.tflite\")\n",
    "print(f\"Original model: {original_size / 1024:.1f} KB\")\n",
    "print(f\"Quantized model: {quantized_size / 1024:.1f} KB\")\n",
    "print(f\"Size reduction: {(1 - quantized_size/original_size) * 100:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
